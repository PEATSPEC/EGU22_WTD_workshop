{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[EGU22 SC5.15 Short course](https://meetingorganizer.copernicus.org/EGU22/session/43185)__\n",
    "# Deriving soil moisture information with optical remote sensing data in R\n",
    "Convener: Iuliia Burdun (iuliia.burdun@aalto.fi)<br>\n",
    "Co-conveners: Michel Bechtold, Viacheslav Komisarenko <br>\n",
    "\n",
    "## Introduction\n",
    "Soil moisture is a key variable needed for application in climatology and hydrology. Knowledge about soil moisture and water table depth (WTD) are important to understand the ecosystems feedback to global climate change. Remote sensing can assist with deriving spatial soil moisture data on a regular basis. Particularly, optical remote sensing can be used to estimate soil moisture with unprecedented satellite archives (>30 years of Landsat and 6 years of Sentinel-2) at high spatial resolution (30 m and 10 m) globally.<br>\n",
    "\n",
    "Optical Trapezoid Model (OPTRAM) has shown high accuracy in soil moisture estimation over mineral and organic soils. OPTRAM is a physically-based approach for remote soil moisture estimation. OPTRAM is based on the response of short-wave infrared (SWIR) reflectance to vegetation water status, which in turn responds to changes of root-zone soil moisture. OPTRAM is based on the assumption that the pixels’ distribution within the STR–normalized difference vegetation index (NDVI) space is associated with their moisture availability. Pixels with the highest STR values along the NDVI gradient represent the so-called ‘wet edge’ and they are assumed to have the wettest conditions. Conversely, the pixels with the lowest STR values along the NDVI gradient represent the ‘dry edge’ and they have the lowest moisture availability. In OPTRAM, wet and dry edges are isopleths of uniform soil moisture conditions in different vegetation covers.\n",
    "\n",
    "<img src=\"https://www.mdpi.com/remotesensing/remotesensing-12-02936/article_deploy/html/images/remotesensing-12-02936-g003.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "The concept of OPTRAM to retrieve a soil moisture index at the point i as a function of NDVI and STR. The wet edge is shown with a blue line and indicated by points *STRs<sub>max</sub>* and *STRc<sub>max</sub>*. The dry edge is shown with the red line and indicated by points *STRs<sub>min</sub>* and *STRc<sub>min</sub>*. The color gradient indicates the transition of moisture condition from the wet to dry edges. Point *i* with *STR<sub>i</sub>* and *NDVI<sub>i</sub>* represents moderate moisture availability. For *i*, the STR values of the wet and dry edges are *STRmax<sub>i</sub>* and *STRmin<sub>i</sub>* correspondingly.<br>\n",
    "\n",
    "\n",
    "\n",
    "The soil moisture content at a given pixel *i* is estimated as follows:\n",
    "\n",
    "\n",
    "\n",
    "${W}_{OPTRAM, i} = \\frac{{STR}_{i} - {STR}_{min, i}}{{STR}_{max, i}-{STR}_{min, i}}\\  $\n",
    "\n",
    "\n",
    "where *OPTRAM<sub>i</sub>* is the soil moisture content of the pixel normalized by the local maximum wet soil content, STR<sub>i</sub> is the STR value of i pixel, STRmax<sub>i</sub> and STRmin<sub>i</sub> are the STR values of the dry and wet edges at the NDVI of pixel *i*. *OPTRAM<sub>i</sub>* values vary between 1 for pixels lying on the wet edge, and 0 for pixels lying on the dry edge. The NDVI and STR values of pixels are derived as:\n",
    "\n",
    "$NDVI = \\frac{{ρ}_{NIR} - {ρ}_{Red}}{{ρ}_{NIR}+{ρ}_{Red}}\\  $,\n",
    "\n",
    "$STR = \\frac{(1-{ρ}_{SWIR})^2}{2{ρ}_{SWIR}}\\  $,\n",
    "\n",
    "where *ρ<sub>NIR<sub>*, *ρ<sub>Red<sub>*, and *ρ<sub>SWIR<sub>* are surface reflectance in the near-infrared (NIR), red, and SWIR wavebands, respectively.<br>\n",
    " \n",
    "In peatlands, the soil moisture is tightly coupled to WTD. Therefore, OPTRAM  is a useful tool to monitor WTD dynamics in peatlands, although the sensitivity of OPTRAM  to WTD changes depend on vegetation cover and related rooting depth. Thus, we sugested an approach that identifies the peatland locations (__[‘best pixels’](https://www.mdpi.com/2072-4292/12/18/2936/htm)__) where the temporal variation of the OPTRAM is most representative of WTD dynamics. The identification of one (or a few) ‘best’ pixels are sufficient to monitor the temporal WTD variations over an entire intact peatland because the high saturated hydraulic conductivity of the upper peat layer sustained largely synchronised temporal WTD fluctuations over a range of a few km. This synchronisation of the dynamics occurred despite small-scale spatial differences in long-term mean WTD.\n",
    "<img src=\" https://www.mdpi.com/remotesensing/remotesensing-12-02936/article_deploy/html/images/remotesensing-12-02936-g001.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "## Data\n",
    "* ###  __[Peatland boundary](https://geoportaal.maaamet.ee/eng/Spatial-Data/Estonian-Topographic-Database-p305.html)__  \n",
    "The boundary of the peatland area was derived from the Estonian Topographic Database.\n",
    "    \n",
    "* ### __[Sentinel-2 MSI surface reflectance data](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR)__\n",
    "We performed cloud masking (applying __[Sentinel-2: Cloud Probability dataset](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_CLOUD_PROBABILITY?hl=en)__) and calculated NDVI and STR in Google Earth Engine for the vegetation period in 2018 (May - September).\n",
    "    \n",
    "* ### __[Water table depth data (WTD)](https://www.ilmateenistus.ee/siseveed/aastaraamatud-ja-bulletaan/soo-aastaraamatud/)__\n",
    "Water table depth (WTD) data were measured at Männikjarve peatland (Tooma mire research station) and provided by the Estonian Environment Agency.\n",
    "    \n",
    "## Workflow  \n",
    "<img src=\"https://www.linkpicture.com/q/Workflow.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries (packages) \"quietly\" with suppressMessages and suppressWarnings functions\n",
    "## Handle geospatial data\n",
    "suppressMessages(suppressWarnings(require(raster))) # reading, writing, manipulating, analyzing of spatial data\n",
    "suppressMessages(suppressWarnings(require(sf))) # work with simple features\n",
    "\n",
    "## Plot data\n",
    "suppressMessages(suppressWarnings(require(ggplot2))) # creating graphics\n",
    "suppressMessages(suppressWarnings(require(ggspatial))) # framework for interacting with spatial data using ggplot2 \n",
    "suppressMessages(suppressWarnings(require(cowplot))) # add-on to ggplot, provides set of themes, functions to align plots\n",
    "suppressMessages(suppressWarnings(require(tmap))) # create thematic maps\n",
    "suppressMessages(suppressWarnings(require(tmaptools))) # facilitates 'tmap'\n",
    "suppressMessages(suppressWarnings(require(viridis))) # provide a series of color maps\n",
    "\n",
    "# Data mutation\n",
    "suppressMessages(suppressWarnings(require(stringr))) #  string manipulations\n",
    "suppressMessages(suppressWarnings(require(dplyr))) # grammar of data manipulation\n",
    "suppressMessages(suppressWarnings(require(stats))) #  statistical calculations and random number generation\n",
    "suppressMessages(suppressWarnings(require(tidyr))) # contains tools for changing the shape and hierarchy of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-2 raster NDVI and STR data exported from GEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Google Earth Engine, you can download the calculated NDVI and STR images as a collection of separate files. Each file - either NDVI or STR image for one date. On the example of one date (03/03/2018), we will show how to handle this type of raster data in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open downloaded Sentinel-2 NDVI data\n",
    "NDVI_raster <- raster(\"S2 image/20180303T093029_20180303T093028_T35VMF_NDVI.tif\")\n",
    "NDVI_raster # see the properties of NDVI RasterLayer\n",
    "\n",
    "# Look at the variable name\n",
    "names(NDVI_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the variable is similar to the file name. \n",
    "# Change the long name \"X20180303T093029_20180303T093028_T35VMF_NDVI\" to  more understandable \"NDVI\"\n",
    "names(NDVI_raster)<- \"NDVI\"\n",
    "names(NDVI_raster) # better readable now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same steps for STR file. \n",
    "# Open downloaded Sentinel-2 STR data\n",
    "STR_raster <- raster(\"S2 image/20180303T093029_20180303T093028_T35VMF_STR.tif\")\n",
    "STR_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the long name to \"STR\"\n",
    "names(STR_raster)\n",
    "names(STR_raster)<- \"STR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the shapefile with peatland boundaries\n",
    "peatland_st <- st_read(\"shp/EE_MAN_4326.shp\") \n",
    "peatland_st # the Bounding box parameters are shown in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether coordinate projections of raster data (STR and NDVI) are the same as for the vector data\n",
    "st_crs(peatland_st) == st_crs(STR_raster) # FALSE means that their projections are not similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the coordinate projections are not the same, we must reproject data. Otherwise, we will face difficulties while plotting these data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform reference system of peatland_st \n",
    "peatland_st <- st_transform (peatland_st, st_crs(STR_raster))\n",
    "st_crs(peatland_st) == st_crs(STR_raster) # TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R has a number of packages and functions that you can use for plotting geospatial data. Let's try some of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) base R function \"plot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot (STR_raster) # plot STR raster\n",
    "plot(peatland_st, border=\"black\", add=TRUE, color = NaN, lwd = 2)# add polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) \"tmap\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_shape(STR_raster)+\n",
    "  tm_raster(style = \"order\", # classification method for data binning\n",
    "            palette = \"-BuPu\", # try other palettes: YlGn, Reds, Greys. \"-\" indicates revers order\n",
    "            n = 3,# number of classes\n",
    "            legend.reverse = \"TRUE\") +\n",
    "  tm_layout(legend.position = c(0.8, .2),  \n",
    "            scale=1)+\n",
    "  tm_scale_bar(position = c(0.1, .01),\n",
    "               breaks = c(0, 0.2),\n",
    "               text.size = 1)+\n",
    "  tm_shape (peatland_st)+\n",
    "  tm_borders(col = \"black\", lwd = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) \"ggplot2\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggplot requires data transformation from raster file to the data frame\n",
    "STR_spdf <- as(STR_raster, \"SpatialPixelsDataFrame\") # define spatial grid\n",
    "STR_df <- as.data.frame(STR_spdf)\n",
    "\n",
    "str(STR_raster) # the initial structure of raster layer\n",
    "str(STR_df) # the structure of data frame\n",
    "head(STR_df, 10) # check the top 10 rows in the new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot transformed STR_df data\n",
    "fig_STR <- ggplot()+\n",
    "  # plot raster file and peatland boundary\n",
    "  geom_raster(data=STR_df, aes(x=x, y=y, fill=STR))+\n",
    "  geom_sf(data = peatland_st, \n",
    "          fill = NA, # no inner fill\n",
    "          colour = \"black\", # boundary colour\n",
    "          size=2)+\n",
    "  # set the colour palette for raster file\n",
    "    scale_fill_gradientn(colours  = c(\"#005b8a\", \"#e5feff\", \"#fdb586\", \n",
    "                                      \"#f23333\", \"#cf001b\", \"#ac0002\", \n",
    "                                      \"#8b0000\", \"#6e031e\",  \"#6b0000\"),\n",
    "                       # brakes in the gradient legend\n",
    "                       breaks = c(4,6,8, 10, 15), \n",
    "                       # set the legend location and other parameters\n",
    "                       guide = guide_colorbar(direction = \"horizontal\",\n",
    "                                              barheight = unit(2, units = \"mm\"),\n",
    "                                              barwidth = unit(50, units = \"mm\"),\n",
    "                                              # set the title above the legend\n",
    "                                              # and in the middle\n",
    "                                              title.position = 'top',\n",
    "                                              title.hjust = 0.5,\n",
    "                                              label.hjust = 0.5))+\n",
    "  #set theme parameters\n",
    "  theme_minimal()+\n",
    "  theme(axis.title = element_blank(),\n",
    "        legend.position = \"bottom\",\n",
    "        legend.key.width = unit(1,\"cm\"),\n",
    "        legend.key.height = unit(0.5,\"cm\"),\n",
    "        legend.text = element_text(size = 15),\n",
    "        legend.title = element_text(size = 17))+\n",
    "  # add scale and north arrow if needed\n",
    "  annotation_scale(location = \"bl\", \n",
    "                   style = \"ticks\",\n",
    "                   text_cex = 1.2) +\n",
    "  annotation_north_arrow(width = unit(0.5, \"cm\"), \n",
    "                         location = \"tl\")+\n",
    "  # set the coordinate referances of the map \n",
    "  coord_sf(datum=st_crs(32635))+ \n",
    "  # set the breaks of the map net\n",
    "  scale_x_continuous(breaks = seq(round(min(STR_df$x), digits = -3),\n",
    "                                  round(max(STR_df$x), digits = -3),\n",
    "                                  500))+\n",
    "  scale_y_continuous(breaks = seq(round(min(STR_df$y), digits = -3),\n",
    "                                  round(max(STR_df$y), digits = -3),\n",
    "                                  500))\n",
    "fig_STR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot NDVI data similarly to STR data. We will use \"ggplot2\" package for NDVI data, but you are free to test the base \"plot\" function and \"tmap\" package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and plot NDVI data\n",
    "NDVI_spdf <- as(NDVI_raster, \"SpatialPixelsDataFrame\")\n",
    "NDVI_df <- as.data.frame(NDVI_spdf)\n",
    "str(NDVI_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NDVI raster file\n",
    "fig_NDVI <- ggplot()+  \n",
    "  # plot raster file and peatland boundary\n",
    "  geom_raster(data=NDVI_df, aes(x=x, y=y, fill=NDVI))+\n",
    "  geom_sf(data = peatland_st, \n",
    "          fill = NA, \n",
    "          colour = \"black\", \n",
    "          size=2)+\n",
    "  # set the colour palette for raster file\n",
    "  scale_fill_gradientn(colours  = c(\"#FCFDE1\", \"#467C46\", \"#040B0B\"), \n",
    "                       guide = guide_colorbar(direction = \"horizontal\",\n",
    "                                              barheight = unit(2, units = \"mm\"),\n",
    "                                              barwidth = unit(50, units = \"mm\"),\n",
    "                                              title.position = 'top',\n",
    "                                              title.hjust = 0.5,\n",
    "                                              label.hjust = 0.5))+\n",
    "  #set theme parameters\n",
    "  theme_minimal()+\n",
    "  theme(axis.title = element_blank(),\n",
    "        legend.position=\"bottom\",\n",
    "        legend.key.width=unit(1,\"cm\"),\n",
    "        legend.key.height = unit(0.5,\"cm\"),\n",
    "        legend.text=element_text(size=15),\n",
    "        legend.title = element_text(size=17))+\n",
    "  # add scale and north arrow if needed\n",
    "  annotation_scale(location = \"bl\", \n",
    "                   style = \"ticks\",\n",
    "                   text_cex = 1.2)  +\n",
    "  annotation_north_arrow(width = unit(0.5, \"cm\"), \n",
    "                         location = \"tl\")+\n",
    "  # set the coordinate referances of the map \n",
    "  coord_sf(datum=st_crs(32635))+ \n",
    "  # set the breaks of the map net\n",
    "  scale_x_continuous(breaks = seq(round(min(NDVI_df$x), digits = -3),\n",
    "                                  round(max(NDVI_df$x), digits = -3),\n",
    "                                  500))+\n",
    "  scale_y_continuous(breaks = seq(round(min(NDVI_df$y), digits = -3),\n",
    "                                  round(max(NDVI_df$y), digits = -3),\n",
    "                                  500))\n",
    "fig_NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both STR and NDVI rasters\n",
    "plot_grid(fig_STR, fig_NDVI, ncol = 2, nrow = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-2 data converted to table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel-2 data were downloaded from Google Earth Engine as .tif raster files and later converted to table format. This is time-consuming, so we have already prepared converted data for you. Nevertheless, the code to convert Sentinel-2 data is given below (no need to run it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to convert STR raster data to csv. \n",
    "# The same algorithm should be applied for NDVI data\n",
    "\n",
    "# files <- list.files(path=\"S2 image/\", full.names=TRUE, pattern=\"*_STR.tif\")\n",
    "# lapply(files , function(x) {\n",
    "#   t <- raster\n",
    "#   filename <- names(t)\n",
    "#   d<- cbind(coordinates(t), v=values(t))\n",
    "#   df<-as.data.frame(d)\n",
    "#   name <-names(t)[1] # load file\n",
    "#   name <-str_sub(name, 2,9)\n",
    "#   date <- as.Date(name , format=\"%Y%m%d\")\n",
    "#   df$date<-date \n",
    "#   names(df)[names(df) == \"v\"] <- \"STR\"\n",
    "#   write.csv(df, file=paste0(\"your path\",filename,\".csv\"))\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The converted csv files can be found in the folder \"S2 data in csv\"\n",
    "STR_filename <- list.files(\"S2 data in csv/\", pattern=\"*_STR.csv\", full.names=TRUE, recursive=FALSE)\n",
    "STR_filename # 15 csv files were created for 15 Sentinel-2 raster files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each file and join them all together\n",
    "STR_tables <- Map(cbind, lapply(STR_filename, data.table::fread, sep=\",\"))\n",
    "STR_table <- do.call(rbind, lapply(STR_tables, subset))\n",
    "head (STR_table, 10) # see the top 10 rows of the table\n",
    "unique (STR_table$Date) # see the dates with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same algorithm for csv file with NDVI data\n",
    "NDVI_filename <- list.files(\"S2 data in csv/\", pattern=\"*_NDVI.csv\", full.names=TRUE, recursive=FALSE)\n",
    "NDVI_filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_tables <- Map(cbind, lapply(NDVI_filename, data.table::fread, sep=\",\"))\n",
    "NDVI_table <- do.call(rbind, lapply(NDVI_tables, subset))\n",
    "head (NDVI_table, 10) # see the top 10 rows of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tables STR_table and NDVI_table by x, y, and Date, since every pixel (with unique x- and y-coordinates) \n",
    "# for each Date has both STR and NDVI values. \n",
    "S2_table <- full_join(STR_table, NDVI_table, by=c(\"x\", \"y\", \"Date\"))\n",
    "str(S2_table) # Are the dates in the Date column are recognised as dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIG fuljoin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove some columns that we don't need (\"V1.x\" and \"V1.y\")\n",
    "S2_table <- S2_table %>% dplyr:: select(-\"V1.x\", -\"V1.y\")\n",
    "\n",
    "# Convert Date column to the date format\n",
    "S2_table$Date <- as.Date(S2_table$Date, format = \"%Y-%m-%d\")\n",
    "\n",
    "# Now we have the table we can further use for OPTRAM calculation. \n",
    "# Every pixel has NDVI and STR values for each date in this table.\n",
    "summary(S2_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the time series of NDVI and STR values for one pixel. For this, we need to know the x and y parameters of the pixel we want to plot. You can choose the random pixel from S2_table. Another option is to plot time series of the pixel with the maximum number of observation days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations are present in S2_table for each pixel (unique x and y)?\n",
    "n_table <- S2_table %>% group_by(x, y)%>% # group by unique x and y values\n",
    "                        summarise(n_obs = n ())\n",
    "\n",
    "summary(n_table)\n",
    "max(n_table$n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From n_table select pixels that have the maximum number of observations\n",
    "n_table <- n_table %>% filter(n_obs == max(n_table$n_obs))\n",
    "n_table # there are 21 pixels with 27 observations\n",
    "n_max <- n_table[1,] # select the first pixel among these 21 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NDVI and STR time series of the selected pixel\n",
    "fig_TS_S2 <- ggplot(subset(S2_table, x %in% n_max$x  & y %in% n_max$y ))+\n",
    "  # add STR \n",
    "  geom_point(aes( x= Date, y=STR), \n",
    "             color= \"#FF8D29\", # show STR with orange colour\n",
    "             size=3.5, \n",
    "             alpha=0.9)+ # alpha set the transparency (0 - transparent, 1 - opaque) \n",
    "  geom_line(aes( x= Date, y=STR), \n",
    "            color= \"#FF8D29\", \n",
    "            size=2, \n",
    "            alpha=0.1)+\n",
    "  # add NDVI\n",
    "  geom_point(aes( x= Date, y=NDVI*10), # scale NDVI to show it on one plot with STR\n",
    "             color= \"#8B9A46\", # show NDVI with green colour\n",
    "             size=3.5, \n",
    "             alpha=0.9)+\n",
    "  geom_line(aes( x= Date, y=NDVI*10), \n",
    "            color= \"#8B9A46\", \n",
    "            size=2, \n",
    "            alpha=0.1)+\n",
    "  # Set the axis\n",
    "  scale_x_date(date_breaks = \"1 month\", \n",
    "               date_labels = \"%d/%m/%Y\")+\n",
    "  scale_y_continuous(name = \"STR\", \n",
    "                     # show NDVI on the secondary axis\n",
    "                     sec.axis = sec_axis(~./10, name= \"NDVI\"))+\n",
    "  # theme parameters\n",
    "  theme_bw()+\n",
    "  theme(axis.title = element_text(size=15),\n",
    "        axis.text = element_text(size=10),\n",
    "        # right axis\n",
    "        axis.line.y.right = element_line(color = \"#8B9A46\"), \n",
    "        axis.ticks.y.right = element_line(color = \"#8B9A46\"),\n",
    "        axis.text.y.right = element_text(color = \"#8B9A46\"), \n",
    "        axis.title.y.right = element_text(color = \"#8B9A46\"),\n",
    "        # left axis\n",
    "        axis.line.y.left = element_line(color = \"#FF8D29\"), \n",
    "        axis.ticks.y.left = element_line(color = \"#FF8D29\"),\n",
    "        axis.text.y.left = element_text(color = \"#FF8D29\"), \n",
    "        axis.title.y.left = element_text(color = \"#FF8D29\")\n",
    "        )\n",
    "fig_TS_S2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTRAM calculation\n",
    "\n",
    "OPTRAM is calculated based on NDVI-STR space. Before the OPTRAM calculation, it is crucial to see what NDVI-STR space looks like for our data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NDVI-STR scatterplot\n",
    "fig_NDVIvsSTR <- ggplot(S2_table, aes(x=NDVI, y=STR))+\n",
    "  geom_point(alpha = 1/80)+\n",
    "  theme_bw()+\n",
    "  theme(axis.title = element_text(size=15),\n",
    "        axis.text = element_text(size=10))\n",
    "fig_NDVIvsSTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the observed NDVI-STR cloud, we can set the parameters \n",
    "# for wet and dry edges\n",
    "minimal_ndvi <- 0.4 # min NDVI value \n",
    "maximal_ndvi <- 0.9 # max NDVI value \n",
    "sub_number <- 10 # number of subintervals in each interval\n",
    "step <- 0.001 #  step for intervals\n",
    "max_i <- (maximal_ndvi - minimal_ndvi) / step\n",
    "print(max_i)\n",
    "total_int_number <- max_i / sub_number # number of intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wet edge\n",
    "Within the NDVI-STR space we derive the max STR value for each NDVI subinterval.This max STR value is arranged with the median NDVI value of each NDVI subinterval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list that we will use to store the data derived in loop\n",
    "median_ndvi_intervals_we <- list()\n",
    "max_str_intervals_we <- list()\n",
    "\n",
    "for (i in 1:max_i) {\n",
    "  # find the max and max NDVI for each subinterval\n",
    "  current_low <- minimal_ndvi + step*(i-1)*(maximal_ndvi - minimal_ndvi)\n",
    "  current_high <- minimal_ndvi + step*i*(maximal_ndvi - minimal_ndvi)\n",
    "  \n",
    "  # filter data that belong to the subinterval\n",
    "  current_df <- S2_table[(S2_table$NDVI < current_high) & \n",
    "                           (S2_table$NDVI >= current_low),]\n",
    "  \n",
    "  # derive the max STR within the subinterval \n",
    "  max_str <- max(current_df$STR)\n",
    "  max_str_intervals_we[[length(max_str_intervals_we)+1]] <- max_str\n",
    "  \n",
    "  # derive the median NDVI value of the subinterval\n",
    "  current_median_ndvi <- median(current_df$NDVI)\n",
    "  median_ndvi_intervals_we[[length(median_ndvi_intervals_we)+1]] <- current_median_ndvi\n",
    "}\n",
    "\n",
    "# max STR values within each NDVI subinterval\n",
    "subinterval_data_we <- data.frame(STR=unlist(max_str_intervals_we), \n",
    "                                  NDVI=unlist(median_ndvi_intervals_we))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each NDVI interval has subintervals within which we derived max STR values. So now, within each interval we calculate the median and std of max STR values.Then, we filter out max STR values that are bigger than median max STR + std max STR. The remained max STR values are averaged (median) and associated with the median NDVI value within each interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_max_str_we <- list()\n",
    "filtered_median_ndvi_we <- list()\n",
    "\n",
    "for (i in 1:total_int_number) {\n",
    "  current_data_chunk <- subinterval_data_we[round((i-1)*sub_number, 0):round(i*sub_number, 0),]\n",
    "  \n",
    "  # Within each interval find the max STR values that is lower than \n",
    "  # median max STR + std max STR\n",
    "  str_threshold <- median(current_data_chunk$STR) + sd(current_data_chunk$STR)\n",
    "  \n",
    "  # Filter based on this condition\n",
    "  filtered_data <- current_data_chunk[current_data_chunk$STR < str_threshold,]\n",
    "  \n",
    "  # Average remained max STR values for each interval and calculate \n",
    "  # median NDVI within each interval\n",
    "  filtered_max_str_we[[length(filtered_max_str_we)+1]] <- median(filtered_data$STR)\n",
    "  filtered_median_ndvi_we[[length(filtered_median_ndvi_we)+1]] <- median(filtered_data$NDVI)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDVI and STR values that are used for further dry edge estimation\n",
    "print(unlist(filtered_max_str_we))\n",
    "\n",
    "# Linear model with all the max STR and NDVI values\n",
    "interval_data <- data.frame(STR=unlist(filtered_max_str_we), \n",
    "                            NDVI=unlist(filtered_median_ndvi_we))\n",
    "relation_wetedge <- lm(STR~NDVI, data=interval_data)\n",
    "coef(relation_wetedge) # coefficients of the linear model\n",
    "\n",
    "intercept_we <- coef(relation_wetedge)[\"(Intercept)\"]\n",
    "intercept_we\n",
    "\n",
    "slope_we <- coef(relation_wetedge)[\"NDVI\"]\n",
    "slope_we"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry edge\n",
    "A similar algorithm is applied for dry edge estimation. For the dry edge, we need to derive the min STR value for each NDVI interval.This min STR value is arranged with the median NDVI value of each NDVI subinterval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ndvi_intervals_de <- list()\n",
    "min_str_intervals_de <- list()\n",
    "\n",
    "for (i in 1:max_i) {\n",
    "  current_low <- minimal_ndvi + step*(i-1)*(maximal_ndvi - minimal_ndvi)\n",
    "  current_high <- minimal_ndvi + step*i*(maximal_ndvi - minimal_ndvi)\n",
    "  \n",
    "  # filter data that belong to the subinterval\n",
    "  current_df <- S2_table[(S2_table$NDVI < current_high) & (S2_table$NDVI >= current_low),]\n",
    "  \n",
    "  # derive the min STR within the subinterval \n",
    "  min_str <- min(current_df$STR)\n",
    "  min_str_intervals_de[[length(min_str_intervals_de)+1]] <- min_str\n",
    "  \n",
    "  # derive the median NDVI value of the  subinterval\n",
    "  current_median_ndvi <- median(current_df$NDVI)\n",
    "  median_ndvi_intervals_de[[length(median_ndvi_intervals_de)+1]] <- current_median_ndvi\n",
    "}\n",
    "\n",
    "# min STR values within each NDVI subinterval\n",
    "subinterval_data_de <- data.frame(STR=unlist(min_str_intervals_de), \n",
    "                                  NDVI=unlist(median_ndvi_intervals_de))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each NDVI interval has subintervals within which we derived min STR values. Similarly to the wet edge calculation, within each interval we calculate the median and std of min STR values. After that, within each interval, we filter out min STR values that are bigger than median min STR - std min STR. The remained min STR values are averaged (median) and associated with the median NDVI value within each interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_min_str_de <- list()\n",
    "filtered_median_ndvi_de <- list()\n",
    "\n",
    "for (i in 1:total_int_number) {\n",
    "  current_data_chunk <- subinterval_data_de[round((i-1)*sub_number, 0):round(i*sub_number, 0),]\n",
    "  \n",
    "  # Within each interval find the max STR values that is lower than median min STR + std min STR\n",
    "  str_threshold <- median(current_data_chunk$STR) - sd(current_data_chunk$STR)\n",
    "  \n",
    "  # Filter based on this condition\n",
    "  filtered_data <- current_data_chunk[current_data_chunk$STR > str_threshold,]\n",
    "  \n",
    "  # Average remained min STR values for each interval and calculate median NDVI within each interval\n",
    "  filtered_min_str_de[[length(filtered_min_str_de)+1]] <- median(filtered_data$STR)\n",
    "  filtered_median_ndvi_de[[length(filtered_median_ndvi_de)+1]] <- median(filtered_data$NDVI)\n",
    "}\n",
    "\n",
    "# NDVI and STR values that are used for further dry edge estimation\n",
    "print(unlist(filtered_min_str_de))\n",
    "\n",
    "# PARAMETERS FOR DRY EDGE\n",
    "# Linear model with all the min STR and NDVI values\n",
    "interval_data <- data.frame(STR=unlist(filtered_min_str_de), NDVI=unlist(filtered_median_ndvi_de))\n",
    "relation_dryedge <- lm(STR~NDVI, data=interval_data)\n",
    "coef(relation_dryedge)\n",
    "\n",
    "intercept_de <- coef(relation_dryedge)[\"(Intercept)\"]\n",
    "intercept_de\n",
    "\n",
    "slope_de <- coef(relation_dryedge)[\"NDVI\"]\n",
    "slope_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dry and wet edges \n",
    "fig_NDVIvsSTR_edges<- fig_NDVIvsSTR +\n",
    "  # Wet edge\n",
    "  geom_abline(intercept = intercept_we, \n",
    "              slope = slope_we, \n",
    "              color = \"#2E94B9\",\n",
    "              size = 2)+\n",
    "  # Dry edge\n",
    "  geom_abline(intercept = intercept_de, \n",
    "              slope = slope_de, \n",
    "              color = \"#FD5959\",\n",
    "              size = 2)\n",
    "fig_NDVIvsSTR_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTRAM calculation\n",
    "S2_table$OPTRAM <- (S2_table$STR - (intercept_de + S2_table$NDVI * slope_de)) /\n",
    "                   ((intercept_we + slope_we * S2_table$NDVI)-(intercept_de + slope_de * S2_table$NDVI ))\n",
    "summary(S2_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixels lying above/below wet/ dry edges have values higher than one and lower than 0. \n",
    "# We will consider those pixels as outliers and assign NaN to their OPTRAM values.\n",
    "S2_table$OPTRAM [S2_table$OPTRAM >1] <- NaN   \n",
    "S2_table$OPTRAM [S2_table$OPTRAM <0] <- NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data = S2_table, aes(x = NDVI, y = STR, color = OPTRAM))+\n",
    "  geom_point(alpha = 1/30)+\n",
    "  # Wet edge\n",
    "  geom_abline(intercept = intercept_we, \n",
    "              slope = slope_we, \n",
    "              color = \"#2E94B9\",\n",
    "              size = 2)+\n",
    "  # Dry edge\n",
    "  geom_abline(intercept = intercept_de, \n",
    "              slope = slope_de, \n",
    "              color = \"#FD5959\",\n",
    "              size = 2)+\n",
    "  # Set gradient color\n",
    "  scale_color_gradient(low=\"#FD5959\",\n",
    "                       high=\"#2E94B9\")+\n",
    "  # Set theme\n",
    "  theme_bw()+\n",
    "  theme(axis.title = element_text(size=20),\n",
    "        axis.text = element_text(size=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation analysis between OPTRAM and water table depth data in peatland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read WTD data\n",
    "WTD_table <- read.csv (\"WTD data/EE_MAN.csv\")\n",
    "\n",
    "str(WTD_table)\n",
    "summary(WTD_table) # What is the date format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WTD_table$Date <- as.Date(WTD_table$Date, format = \"%d/%m/%Y\")\n",
    "str(WTD_table) # better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time-series of NDVI and STR for one pixel together with WTD data\n",
    "fig_TS_WTD <- ggplot(WTD_table, aes(x = Date, y = WTD))+\n",
    "  geom_ribbon(aes(ymin = min(WTD,na.rm = TRUE)-1 , ymax= WTD),\n",
    "              fill=\"#7FB5FF\", alpha = 0.7)+\n",
    "  theme_bw()+\n",
    "  theme(axis.title = element_text(size=15),\n",
    "        axis.text = element_text(size=10))+\n",
    "  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m/%Y\",\n",
    "               limits = c(as.Date(\"1/05/2018\", format = \"%d/%m/%Y\"),\n",
    "                      as.Date(\"1/09/2018\", format = \"%d/%m/%Y\")))\n",
    "fig_TS_WTD\n",
    "\n",
    "plot_grid(fig_TS_S2, fig_TS_WTD, ncol = 1, nrow = 2, align = \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join WTD_table and S2_table\n",
    "data_table <- full_join(WTD_table, S2_table, by = \"Date\")\n",
    "str(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we calculate correlation between OPTRAM and WTD, we need to filter out \n",
    "# pixels with only few values, since cor.test will result in error\n",
    "data_table_n <- data_table %>%\n",
    "  group_by(x,y) %>% # group all the pixels by their unique coordinates\n",
    "  mutate(n_obs = n()) %>% # mutate a new column that with the number of observations for each pixel\n",
    "  ungroup()\n",
    "\n",
    "summary(data_table_n) # what are the min and max number of observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out pixels that have less than 10 observations from data_table_n\n",
    "data_table_n <- data_table_n %>% filter (n_obs > 10)\n",
    "\n",
    "# Calculate the Pearson correlation and p-values between OPTRAM and WTD time-series for each pixel remained in data_table_n\n",
    "data_table_cor<-data_table_n%>%\n",
    "  dplyr::select(x,y, WTD, OPTRAM)%>% # select these columns only\n",
    "  group_by(x,y) %>% \n",
    "  dplyr::summarize(R_pvalue=cor.test(WTD, OPTRAM, use=\"pairwise.complete.obs\")$p.value, # p-value\n",
    "                   R=cor.test(WTD, OPTRAM, use=\"pairwise.complete.obs\")$estimate) # correlation coefficient\n",
    "\n",
    "summary(data_table_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the per-pixel correlation coefficients\n",
    "ggplot()+  \n",
    "  geom_raster(data=data_table_cor, aes(x=x, y=y, fill=R))+\n",
    "  scale_fill_viridis(\n",
    "    option = \"inferno\",\n",
    "    direction = 1,\n",
    "    name = \"R\",\n",
    "    guide = guide_colorbar(\n",
    "      direction = \"horizontal\",\n",
    "      barheight = unit(2, units = \"mm\"),\n",
    "      barwidth = unit(50, units = \"mm\"),\n",
    "      draw.ulim = F,\n",
    "      title.position = 'top',\n",
    "      title.hjust = 0.5,\n",
    "      label.hjust = 0.5\n",
    "    ))+\n",
    "  theme_minimal()+\n",
    "  theme(axis.title = element_blank(),\n",
    "        legend.position=\"bottom\",\n",
    "        legend.key.width=unit(1,\"cm\"),\n",
    "        legend.key.height = unit(0.5,\"cm\"),\n",
    "        legend.text=element_text(size=15),\n",
    "        legend.title = element_text(size=17))+\n",
    "  \n",
    "  annotation_scale(location = \"bl\", \n",
    "                   style = \"ticks\",\n",
    "                   text_cex = 1.2)  +\n",
    "  annotation_north_arrow(width = unit(0.5, \"cm\"), location = \"tl\")+ \n",
    "  coord_equal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step - select the \"best pixel\" based on the correlation results\n",
    "# First, select pixels with p-values lower than 0.05\n",
    "data_table_bestcor <- data_table_cor %>% filter (R_pvalue < 0.05)\n",
    "\n",
    "# Second, among the remained pixels select the one with the highest correlation value\n",
    "data_table_bestcor <- data_table_bestcor[which.max(data_table_bestcor$R),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot WTD time series with OPTRAM time series\n",
    "fig_TS_WTD+\n",
    "  geom_point(data = subset(data_table, x %in% data_table_bestcor$x  & y %in% data_table_bestcor$y),\n",
    "             aes(x = Date, y = OPTRAM*85-65),\n",
    "             color = \"#FF165D\",\n",
    "             size = 2)+\n",
    "  geom_segment(data = subset(data_table, x %in% data_table_bestcor$x  & y %in% data_table_bestcor$y),\n",
    "                aes(x = Date, \n",
    "                    xend=Date, \n",
    "                    y=min(WTD,na.rm = TRUE)-1, \n",
    "                    yend=OPTRAM*85-65),\n",
    "                alpha=0.1,\n",
    "                color = \"#FF165D\")+\n",
    "  scale_y_continuous(name = \"STR\", \n",
    "                     sec.axis = sec_axis((~./85 + 65/85), name= \"OPTRAM\"))+\n",
    "  theme(axis.line.y.right = element_line(color = \"#FF165D\"), \n",
    "        axis.ticks.y.right = element_line(color = \"#FF165D\"),\n",
    "        axis.text.y.right = element_text(color = \"#FF165D\"), \n",
    "        axis.title.y.right = element_text(color = \"#FF165D\"),\n",
    "        \n",
    "        axis.line.y.left = element_line(color = \"#7FB5FF\"), \n",
    "        axis.ticks.y.left = element_line(color = \"#7FB5FF\"),\n",
    "        axis.text.y.left = element_text(color = \"#7FB5FF\"), \n",
    "        axis.title.y.left = element_text(color = \"#7FB5FF\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of maps of OPTRAM \n",
    "ggplot()+\n",
    "  geom_raster(data=S2_table, aes(x=x, y=y, fill=OPTRAM))+ \n",
    "  coord_equal()+\n",
    "  scale_fill_gradientn(colours  = c(\"#f94144\", \"#faf3dd\", \"#2a6f97\", \"#014f86\", \n",
    "                                    \"#01497c\",  \"#012a4a\"), \n",
    "                       na.value = \"#F0F0F0\",\n",
    "                       limits = c(0,1),\n",
    "                       breaks = c(0, 0.5, 1),\n",
    "                       guide = guide_colorbar(direction = \"horizontal\",\n",
    "                                              barheight = unit(2, units = \"mm\"),\n",
    "                                              barwidth = unit(50, units = \"mm\"),\n",
    "                                              draw.ulim = F,\n",
    "                                              title.position = 'top',\n",
    "                                              title.hjust = 0.5,\n",
    "                                              label.hjust = 0.5))+\n",
    "  theme_void()+\n",
    "  theme(axis.title = element_blank(),\n",
    "        legend.position=\"bottom\",\n",
    "        legend.key.width=unit(1,\"cm\"),\n",
    "        legend.key.height = unit(0.5,\"cm\"),\n",
    "        legend.text=element_text(size=15),\n",
    "        legend.title = element_text(size=17))+\n",
    "  # Add location of the \"best pixel\"\n",
    "  geom_point(data = subset(S2_table, x %in% data_table_bestcor$x  & \n",
    "                             y %in% data_table_bestcor$y),\n",
    "             aes(x = x, y = y),\n",
    "             shape = 5,\n",
    "             color = \"#F900BF\",\n",
    "             size = 2,\n",
    "             stroke = 2)+\n",
    "  facet_wrap(Date ~ ., ncol = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
